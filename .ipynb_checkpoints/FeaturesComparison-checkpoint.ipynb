{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from statistics import mean, median\n",
    "from data_parser import DataParser\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from prettytable import PrettyTable\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IKEA_APP = \"annotated-datasets/ikea-app\"\n",
    "IKEA_HOMEKIT = \"annotated-datasets/ikea-homekit\"\n",
    "IP_CAM = \"annotated-datasets/ipcam\"\n",
    "NORMAL_USER = \"annotated-datasets/normal-user\"\n",
    "VOICE_ASSISTANT = \"annotated-datasets/voice-assistant\"\n",
    "PROCESS_DATASETS = [IP_CAM]\n",
    "FIND_VALUE = [\"NetBIOS\"]\n",
    "SKIP_VALUES = [\"Flow Error\"]\n",
    "ENABLE_FILTER = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalar Features\n",
    "wht1 = []\n",
    "wht2 = []\n",
    "wht3 = []\n",
    "wht4 = []\n",
    "entropy = []\n",
    "byte_dist_std = []\n",
    "byte_dist_mean = []\n",
    "pkts_in = []\n",
    "pkts_out = []\n",
    "bytes_in = []\n",
    "bytes_out = []\n",
    "flow_time = []\n",
    "ttl_in = []\n",
    "ttl_out = []\n",
    "src_port = set()\n",
    "dst_port = set()\n",
    "total_len = 0\n",
    "data = [] \n",
    "\n",
    "for dataset in PROCESS_DATASETS:\n",
    "    for root, dirs, files in os.walk(dataset):\n",
    "        if dirs:\n",
    "            continue\n",
    "        for file in files:\n",
    "            # Get values from raw flows\n",
    "            dParse = DataParser(root+\"/\"+file,analyse=1,compact=1)\n",
    "            tmp = dParse.getIndividualFlowMetadata()\n",
    "            with open(root+\"/\"+file,encoding=\"utf-8\", mode=\"r\") as flows:\n",
    "                index = 0 \n",
    "                for flow in flows:\n",
    "                    flowData = json.loads(flow)\n",
    "                    if (flowData[\"flow_type\"] not in FIND_VALUE and ENABLE_FILTER) or flowData[\"flow_type\"] in SKIP_VALUES: # Annotated class name\n",
    "                        # If flow type is different -> move also feature index\n",
    "                        index += 1\n",
    "                        continue\n",
    "                    # Count number of flows for the specific \"dataset\"\n",
    "                    total_len += 1\n",
    "                \n",
    "                    # Add WHT\n",
    "                    if \"wht\" in flowData:\n",
    "                        whtFields = list(flowData[\"wht\"])\n",
    "                        wht1.append(whtFields[0])\n",
    "                        wht2.append(whtFields[1])\n",
    "                        wht3.append(whtFields[2])\n",
    "                        wht4.append(whtFields[3])\n",
    "                    else:\n",
    "                        wht1.append(0)\n",
    "                        wht2.append(0)\n",
    "                        wht3.append(0)\n",
    "                        wht4.append(0)\n",
    "                    # Add Byte_dist_std\n",
    "                    if \"byte_dist_std\" in flowData:\n",
    "                        byte_dist_std.append(flowData[\"byte_dist_std\"])\n",
    "                    else:\n",
    "                        byte_dist_std.append(0)\n",
    "                    # Add byte_dist_mean\n",
    "                    if \"byte_dist_mean\" in flowData:\n",
    "                        byte_dist_mean.append(flowData[\"byte_dist_mean\"])\n",
    "                    else:\n",
    "                        byte_dist_mean.append(0)\n",
    "                    # Add entropy\n",
    "                    if \"entropy\" in flowData:\n",
    "                        entropy.append(flowData[\"entropy\"])\n",
    "                    else:\n",
    "                        entropy.append(0)\n",
    "                    # total_entropy -> doesn't make any sense -> reduced value is the same as entropy\n",
    "                    # Add TTL\n",
    "                    try:\n",
    "                        ttl_in.append(flowData[\"ip\"][\"in\"][\"ttl\"])\n",
    "                    except Exception as e:\n",
    "                        ttl_in.append(0)\n",
    "                    try:\n",
    "                        ttl_out.append(flowData[\"ip\"][\"out\"][\"ttl\"])\n",
    "                    except Exception as e:\n",
    "                        ttl_out.append(0)\n",
    "                        \n",
    "                    #try:\n",
    "                    #    # Add wht\n",
    "                    #    whtFields = list(flowData[\"wht\"])\n",
    "                    #    wht1.append(whtFields[0])\n",
    "                    #    wht2.append(whtFields[1])\n",
    "                    #    wht3.append(whtFields[2])\n",
    "                    #    wht4.append(whtFields[3])\n",
    "                    #    #Add byte_dist_std\n",
    "                    #    byte_dist_std.append(flowData[\"byte_dist_std\"])\n",
    "                    #    #Add byte_dist_mean\n",
    "                    #    byte_dist_mean.append(flowData[\"byte_dist_mean\"])\n",
    "                    #    #Add entropy\n",
    "                    #    entropy.append(flowData[\"entropy\"])\n",
    "                    #except Exception as e:\n",
    "                    #    pass\n",
    "\n",
    "                    #Add preprocessed features\n",
    "                    #These features are always in the extended flow record\n",
    "                    pkts_in.append(tmp[index][0])\n",
    "                    pkts_out.append(tmp[index][1])\n",
    "                    bytes_in.append(tmp[index][2])\n",
    "                    bytes_out.append(tmp[index][3])\n",
    "                    flow_time.append(tmp[index][4])\n",
    "                    src_port.add(flowData[\"sp\"])\n",
    "                    dst_port.add(flowData[\"dp\"])\n",
    "                    index += 1\n",
    "                    #except Exception as e:\n",
    "                    #    pass\n",
    "                    \n",
    "    print(\"DATASET:\", dataset, total_len)  \n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"NAME\",\"MIN\", \"MAX\", \"MEAN\", \"MEDIAN\"]\n",
    "  \n",
    "    table.add_row([\"WHT1\",min(wht1),max(wht1),mean(wht1),median(wht1)])\n",
    "    table.add_row([\"WHT2\",min(wht2),max(wht2),mean(wht2),median(wht2)])\n",
    "    table.add_row([\"WHT3\",min(wht3),max(wht3),mean(wht3),median(wht3)])\n",
    "    table.add_row([\"WHT4\",min(wht4),max(wht4),mean(wht4),median(wht4)])\n",
    "    table.add_row([\"Byte_dist_mean\",min(byte_dist_mean),max(byte_dist_mean),mean(byte_dist_mean),median(byte_dist_mean)])\n",
    "    table.add_row([\"Byte_dist_std\",min(byte_dist_std),max(byte_dist_std),mean(byte_dist_std),median(byte_dist_std)])\n",
    "    table.add_row([\"Entropy\",min(entropy),max(entropy),mean(entropy),median(entropy)])\n",
    "        \n",
    "    table.add_row([\"Pkts_in\",min(pkts_in),max(pkts_in),mean(pkts_in),median(pkts_in)])\n",
    "    table.add_row([\"Pkts_out\",min(pkts_out),max(pkts_out),mean(pkts_out),median(pkts_out)])\n",
    "    table.add_row([\"Bytes_in\",min(bytes_in),max(bytes_in),mean(bytes_in),median(bytes_in)])\n",
    "    table.add_row([\"Bytes_out\",min(bytes_out),max(bytes_out),mean(bytes_out),median(bytes_out)])\n",
    "    table.add_row([\"Flow_time\",min(flow_time),max(flow_time),mean(flow_time),median(flow_time)])\n",
    "    table.add_row([\"TTL in\",min(ttl_in),max(ttl_in),mean(ttl_in),median(ttl_in)])\n",
    "    table.add_row([\"TTL out\",min(ttl_out),max(ttl_out),mean(ttl_out),median(ttl_out)])\n",
    "    print(table)\n",
    "    print(\"Used Source Ports:\",src_port)\n",
    "    print(\"Used Destination Ports:\",dst_port)\n",
    "    \n",
    "    # Plot data\n",
    "    fig1 = plt.figure(1, figsize=(12, 7))\n",
    "    pl11 = fig1.add_subplot(221)\n",
    "    pl11.bar(range(len(wht1)),wht1)\n",
    "    pl11.set_title(\"WHT 1\")\n",
    "    pl12 = fig1.add_subplot(222)\n",
    "    pl12.bar(range(len(wht2)),wht2)\n",
    "    pl12.set_title(\"WHT 2\")\n",
    "    pl13 = fig1.add_subplot(223)\n",
    "    pl13.bar(range(len(wht3)),wht3)\n",
    "    pl13.set_title(\"WHT 3\")\n",
    "    pl14 = fig1.add_subplot(224)\n",
    "    pl14.bar(range(len(wht4)),wht4)\n",
    "    pl14.set_title(\"WHT 4\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig2 = plt.figure(2, figsize=(12, 3))\n",
    "    pl21 = fig2.add_subplot(121)\n",
    "    pl21.bar(range(len(byte_dist_mean)),byte_dist_mean)\n",
    "    pl21.set_title(\"Byte Dist Mean\")\n",
    "    pl22 = fig2.add_subplot(122)\n",
    "    pl22.bar(range(len(byte_dist_std)),byte_dist_std)\n",
    "    pl22.set_title(\"Byte Dist Std\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig3 = plt.figure(3, figsize=(12, 7))\n",
    "    pl31 = fig3.add_subplot(221)\n",
    "    pl31.bar(range(len(pkts_in)),pkts_in)\n",
    "    pl31.set_title(\"Packets IN\")\n",
    "    pl32 = fig3.add_subplot(222)\n",
    "    pl32.bar(range(len(pkts_out)),pkts_out)\n",
    "    pl32.set_title(\"Packets OUT\")\n",
    "    pl33 = fig3.add_subplot(223)\n",
    "    pl33.bar(range(len(bytes_in)),bytes_in)\n",
    "    pl33.set_title(\"Bytes IN\")\n",
    "    pl34 = fig3.add_subplot(224)\n",
    "    pl34.bar(range(len(bytes_out)),bytes_out)\n",
    "    pl34.set_title(\"Bytes OUT\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig4 = plt.figure(4, figsize=(12, 7))\n",
    "    pl41 = fig4.add_subplot(211)\n",
    "    pl41.bar(range(len(flow_time)),flow_time)\n",
    "    pl41.set_title(\"Flow Time\")\n",
    "    pl42 = fig1.add_subplot(212)\n",
    "    pl42.bar(range(len(entropy)),entropy)\n",
    "    pl42.set_title(\"Bytes OUT\")\n",
    "    plt.show()\n",
    "    \n",
    "    fig11 = plt.figure(11, figsize=(12, 7))\n",
    "    pl111 = fig11.add_subplot(211)\n",
    "    pl111.bar(range(len(ttl_in)),ttl_in)\n",
    "    pl111.set_title(\"TTL in\")\n",
    "    pl112 = fig11.add_subplot(212)\n",
    "    pl112.bar(range(len(ttl_out)),ttl_out)\n",
    "    pl112.set_title(\"TTL out\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDP Feature\n",
    "IDP_IN_Byte_Dist = []*256\n",
    "IDP_OUT_Byte_Dist = []*256\n",
    "IDP_LEN_IN = []\n",
    "IDP_LEN_OUT = []\n",
    "total_len = 0\n",
    "total_idp_cnt = 0\n",
    "\n",
    "for dataset in PROCESS_DATASETS:\n",
    "    for root, dirs, files in os.walk(dataset):\n",
    "        if dirs:\n",
    "            continue\n",
    "        for file in files:\n",
    "            with open(root+\"/\"+file,encoding=\"utf-8\", mode=\"r\") as flows:\n",
    "                for flow in flows:\n",
    "                    flowData = json.loads(flow)\n",
    "                    IDP_IN_Byte_Dist_Tmp = [0]*256\n",
    "                    IDP_OUT_Byte_Dist_Tmp = [0]*256\n",
    "                    if flowData[\"flow_type\"] not in FIND_VALUE and ENABLE_FILTER or flowData[\"flow_type\"] in SKIP_VALUES: # Annotated class name\n",
    "                        continue\n",
    "                    total_len += 1\n",
    "                    \n",
    "                    # Process IDP_LEN_IN\n",
    "                    if \"idp_len_in\" in flowData: \n",
    "                        IDP_LEN_IN.append(flowData[\"idp_len_in\"])\n",
    "                        for byte in range(256):\n",
    "                            try:\n",
    "                                IDP_IN_Byte_Dist_Tmp[ord(flowData[\"idp_in\"][byte])] += 1\n",
    "                            # IDP is too short\n",
    "                            except IndexError as ie:\n",
    "                                continue\n",
    "                    else:\n",
    "                        IDP_LEN_IN.append(0)\n",
    "                     \n",
    "                    # Process IDP_LEN_OUT\n",
    "                    if \"idp_len_out\" in flowData:\n",
    "                        IDP_LEN_OUT.append(flowData[\"idp_len_out\"])\n",
    "                        for byte in range(256):\n",
    "                            try:\n",
    "                                IDP_OUT_Byte_Dist_Tmp[ord(flowData[\"idp_out\"][byte])] += 1\n",
    "                            # IDP is too short\n",
    "                            except IndexError as ie:\n",
    "                                continue\n",
    "                    else:\n",
    "                        IDP_LEN_OUT.append(0)\n",
    "                        \n",
    "                    #try:\n",
    "                    #    IDP_LEN_IN.append(flowData[\"idp_len_in\"])\n",
    "                    #    IDP_LEN_OUT.append(flowData[\"idp_len_out\"])\n",
    "                    #    for byte in range(256):\n",
    "                    #        try:\n",
    "                    #            IDP_OUT_Byte_Dist_Tmp[ord(flowData[\"idp_out\"][byte])] += 1\n",
    "                    #            IDP_IN_Byte_Dist_Tmp[ord(flowData[\"idp_in\"][byte])] += 1\n",
    "                    #        # IDP is too short\n",
    "                    #        except IndexError as ie:\n",
    "                    #            continue\n",
    "                    # IDP (IN or OUT) is missing\n",
    "                    #except Exception as e:\n",
    "                    #    continue\n",
    "                        \n",
    "                    total_idp_cnt += 1\n",
    "                    IDP_IN_Byte_Dist.append(IDP_IN_Byte_Dist_Tmp)\n",
    "                    IDP_OUT_Byte_Dist.append(IDP_OUT_Byte_Dist_Tmp)\n",
    "                        \n",
    "    IDP_IN_Byte_Dist_Min = [0]*256\n",
    "    IDP_IN_Byte_Dist_Max = [0]*256\n",
    "    IDP_IN_Byte_Dist_Mean = [0]*256\n",
    "    IDP_IN_Byte_Dist_Median = [0]*256\n",
    "    \n",
    "    IDP_OUT_Byte_Dist_Min = [0]*256\n",
    "    IDP_OUT_Byte_Dist_Max = [0]*256\n",
    "    IDP_OUT_Byte_Dist_Mean = [0]*256\n",
    "    IDP_OUT_Byte_Dist_Median = [0]*256\n",
    "    \n",
    "    print(\"DATASET:\", dataset, total_len, total_idp_cnt)  \n",
    "    \n",
    "    # Save values for IDP_IN\n",
    "    array = np.array(IDP_IN_Byte_Dist)\n",
    "    for no,i in enumerate(array.T):\n",
    "        IDP_IN_Byte_Dist_Min[no] = min(i)\n",
    "        IDP_IN_Byte_Dist_Max[no] = max(i)\n",
    "        IDP_IN_Byte_Dist_Mean[no] = mean(i)\n",
    "        IDP_IN_Byte_Dist_Median[no] = median(i)\n",
    "    # Save values for IDP_OUT\n",
    "    array = np.array(IDP_OUT_Byte_Dist)\n",
    "    for no,i in enumerate(array.T):\n",
    "        IDP_OUT_Byte_Dist_Min[no] = min(i)\n",
    "        IDP_OUT_Byte_Dist_Max[no] = max(i)\n",
    "        IDP_OUT_Byte_Dist_Mean[no] = mean(i)\n",
    "        IDP_OUT_Byte_Dist_Median[no] = median(i)\n",
    "    print(\"IDP IN - Min\")\n",
    "    print(IDP_IN_Byte_Dist_Min)\n",
    "    print(\"IDP IN - Max\")\n",
    "    print(IDP_IN_Byte_Dist_Max)\n",
    "    print(\"IDP IN - Mean\")\n",
    "    print(IDP_IN_Byte_Dist_Mean)\n",
    "    print(\"IDP IN - Median\")\n",
    "    print(IDP_IN_Byte_Dist_Median)\n",
    "    \n",
    "    fig5 = plt.figure(5, figsize=(12, 7))\n",
    "    pl51 = fig5.add_subplot(411)\n",
    "    pl51.bar(range(0,256), IDP_IN_Byte_Dist_Min,color=\"g\")\n",
    "    pl51.set_title(\"IDP IN Min\")\n",
    "    pl52 = fig5.add_subplot(412)\n",
    "    pl52.bar(range(0,256), IDP_IN_Byte_Dist_Max,color=\"r\")\n",
    "    pl52.set_title(\"IDP IN Max\")\n",
    "    pl53 = fig5.add_subplot(413)\n",
    "    pl53.bar(range(0,256), IDP_IN_Byte_Dist_Mean,color=\"b\")\n",
    "    pl53.set_title(\"IDP IN Mean\")\n",
    "    pl54 = fig5.add_subplot(414)\n",
    "    pl54.bar(range(0,256), IDP_IN_Byte_Dist_Median,color=\"m\")\n",
    "    pl54.set_title(\"IDP IN Median\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    print(\"IDP OUT\")\n",
    "    print(\"IDP OUT - Min\")\n",
    "    print(IDP_OUT_Byte_Dist_Min)\n",
    "    print(\"IDP OUT - Max\")\n",
    "    print(IDP_OUT_Byte_Dist_Max)\n",
    "    print(\"IDP OUT - Mean\")\n",
    "    print(IDP_OUT_Byte_Dist_Mean)\n",
    "    print(\"IDP OUT - Median\")\n",
    "    print(IDP_OUT_Byte_Dist_Median)\n",
    "    \n",
    "    fig6 = plt.figure(6, figsize=(12, 7))\n",
    "    pl61 = fig6.add_subplot(411)\n",
    "    pl61.bar(range(0,256), IDP_OUT_Byte_Dist_Min,color=\"g\")\n",
    "    pl61.set_title(\"IDP OUT Min\")\n",
    "    pl62 = fig6.add_subplot(412)\n",
    "    pl62.bar(range(0,256), IDP_OUT_Byte_Dist_Max,color=\"r\")\n",
    "    pl62.set_title(\"IDP OUT Max\")\n",
    "    pl63 = fig6.add_subplot(413)\n",
    "    pl63.bar(range(0,256), IDP_OUT_Byte_Dist_Mean,color=\"b\")\n",
    "    pl63.set_title(\"IDP OUT Mean\")\n",
    "    pl64 = fig6.add_subplot(414)\n",
    "    pl64.bar(range(0,256), IDP_OUT_Byte_Dist_Median,color=\"m\")\n",
    "    pl64.set_title(\"IDP OUT Median\")\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"NAME\",\"MIN\", \"MAX\", \"MEAN\", \"MEDIAN\"]\n",
    "    table.add_row([\"IDP_LEN_in\",min(IDP_LEN_IN),max(IDP_LEN_IN),mean(IDP_LEN_IN),median(IDP_LEN_IN)])\n",
    "    table.add_row([\"IDP_LEN_out\",min(IDP_LEN_OUT),max(IDP_LEN_OUT),mean(IDP_LEN_OUT),median(IDP_LEN_OUT)])\n",
    "    print(table)\n",
    "    \n",
    "    fig7 = plt.figure(7, figsize=(12, 7))\n",
    "    pl71 = fig7.add_subplot(211)\n",
    "    pl71.bar(range(len(IDP_LEN_IN)), IDP_LEN_IN,color=\"y\")\n",
    "    pl71.set_title(\"IDP IN LEN\")\n",
    "    pl72 = fig7.add_subplot(212)\n",
    "    pl72.bar(range(len(IDP_LEN_OUT)), IDP_LEN_OUT,color=\"y\")\n",
    "    pl72.set_title(\"IDP OUT LEN\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Byte Distribution Feature\n",
    "Byte_Dist = []*256\n",
    "total_len = 0\n",
    "byte_dist_cnt = 0\n",
    "for dataset in PROCESS_DATASETS:\n",
    "    for root, dirs, files in os.walk(dataset):\n",
    "        if dirs:\n",
    "            continue\n",
    "        for file in files:\n",
    "            with open(root+\"/\"+file,encoding=\"utf-8\", mode=\"r\") as flows:\n",
    "                for flow in flows:\n",
    "                    flowData = json.loads(flow)\n",
    "                    Byte_Dist_Tmp = [0]*256\n",
    "                    if flowData[\"flow_type\"] not in FIND_VALUE and ENABLE_FILTER or flowData[\"flow_type\"] in SKIP_VALUES: # Annotated class name \n",
    "                        continue\n",
    "                    total_len += 1\n",
    "                    if \"byte_dist\" in flowData:\n",
    "                    #try:\n",
    "                        Byte_Dist.append(flowData[\"byte_dist\"])\n",
    "                    #except Exception as e:\n",
    "                    else: \n",
    "                        Byte_Dist.append([0]*256)\n",
    "                        #continue\n",
    "                    \n",
    "    Byte_Dist_Min = [0]*256\n",
    "    Byte_Dist_Max = [0]*256\n",
    "    Byte_Dist_Mean = [0]*256\n",
    "    Byte_Dist_Median = [0]*256\n",
    "    \n",
    "    print(\"DATASET:\", dataset, total_len)  \n",
    "    array = np.array(Byte_Dist)\n",
    "    # Count Byte Distribution rate for each index in all flows\n",
    "    for no,i in enumerate(array.T):\n",
    "        Byte_Dist_Min[no] = min(i)\n",
    "        Byte_Dist_Max[no] = max(i)\n",
    "        Byte_Dist_Mean[no] = mean(i)\n",
    "        Byte_Dist_Median[no] = median(i)\n",
    "\n",
    "    #print(\"Byte Dist - Min\")\n",
    "    #print(Byte_Dist_Min)\n",
    "    #print(\"Byte Dist - Max\")\n",
    "    #print(Byte_Dist_Max)\n",
    "    #print(\"Byte Dist - Mean\")\n",
    "    #print(Byte_Dist_Mean)\n",
    "    #print(\"Byte Dist - Median\")\n",
    "    #print(Byte_Dist_Median)\n",
    "\n",
    "     # Plot Byte Distribution rate\n",
    "    fig8 = plt.figure(8, figsize=(12, 7))\n",
    "    pl81 = fig8.add_subplot(411)\n",
    "    pl81.bar(range(0,256), Byte_Dist_Min,color=\"g\")\n",
    "    pl81.set_title(\"Byte Dist Min\")\n",
    "    pl82 = fig8.add_subplot(412)\n",
    "    pl82.bar(range(0,256), Byte_Dist_Max,color=\"r\")\n",
    "    pl82.set_title(\"Byte Dist Max\")\n",
    "    pl83 = fig8.add_subplot(413)\n",
    "    pl83.bar(range(0,256), Byte_Dist_Mean,color=\"b\")\n",
    "    pl83.set_title(\"Byte Dist Mean\")\n",
    "    pl84 = fig8.add_subplot(414)\n",
    "    pl84.bar(range(0,256), Byte_Dist_Median,color=\"m\")\n",
    "    pl84.set_title(\"Byte Dist Median\")\n",
    "    plt.show()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLT Feature\n",
    "FLAT_MATRIX_SIZE = 100 # This value depends on data_parser parameters (numRows,binSize) configuration\n",
    "data = [] \n",
    "IPT_Data = []\n",
    "PL_Data = []\n",
    "for dataset in PROCESS_DATASETS:\n",
    "    for root, dirs, files in os.walk(dataset):\n",
    "        if dirs:\n",
    "            continue\n",
    "        for file in files:  \n",
    "            # Count features from IPT and PL\n",
    "            dParse = DataParser(root+\"/\"+file,analyse=1,compact=1)\n",
    "            tmpIPT = dParse.getIndividualFlowIPTs()\n",
    "            tmpPL = dParse.getIndividualFlowPacketLengths()\n",
    "            \n",
    "            # Open file with annotated date for filtering purpose\n",
    "            with open(root+\"/\"+file,encoding=\"utf-8\", mode=\"r\") as flows:\n",
    "                index = 0\n",
    "                for flow in flows:\n",
    "                    flowData = json.loads(flow)\n",
    "                    if flowData[\"flow_type\"] not in FIND_VALUE and ENABLE_FILTER or flowData[\"flow_type\"] in SKIP_VALUES: # Annotated class name\n",
    "                        index += 1\n",
    "                        continue\n",
    "                    # Based on flow possition select appropriate feature vector \n",
    "                    IPT_Data.append(tmpIPT[index])\n",
    "                    PL_Data.append(tmpPL[index])\n",
    "                    index += 1\n",
    "    \n",
    "    # Create list of values for plotting\n",
    "    IPT_Data_Min = [0] * FLAT_MATRIX_SIZE\n",
    "    IPT_Data_Max = [0] * FLAT_MATRIX_SIZE\n",
    "    IPT_Data_Mean = [0] * FLAT_MATRIX_SIZE\n",
    "    IPT_Data_Median = [0] * FLAT_MATRIX_SIZE\n",
    "    \n",
    "    PL_Data_Min = [0] * FLAT_MATRIX_SIZE\n",
    "    PL_Data_Max = [0] * FLAT_MATRIX_SIZE\n",
    "    PL_Data_Mean = [0] * FLAT_MATRIX_SIZE\n",
    "    PL_Data_Median = [0] * FLAT_MATRIX_SIZE\n",
    "    \n",
    "    # Count IPT rate for each index in all flows\n",
    "    tmp_array = np.array(IPT_Data)\n",
    "    for no,i in enumerate(tmp_array.T):\n",
    "        IPT_Data_Min[no] = min(i)\n",
    "        IPT_Data_Max[no] = max(i)\n",
    "        IPT_Data_Mean[no] = mean(i)\n",
    "        IPT_Data_Median[no] = median(i)\n",
    "    \n",
    "    # Count PL rate for each index in all flows\n",
    "    tmp_array = np.array(PL_Data)\n",
    "    for no,i in enumerate(tmp_array.T):\n",
    "        PL_Data_Min[no] = min(i)\n",
    "        PL_Data_Max[no] = max(i)\n",
    "        PL_Data_Mean[no] = mean(i)\n",
    "        PL_Data_Median[no] = median(i)\n",
    "    \n",
    "    #plot SPLT in matrix graph\n",
    "    #for i in range(len(IPT_Data)):\n",
    "    #    print(IPT_Data[i])\n",
    "    #    print(PL_Data[i])\n",
    "    #    #plt.matshow(IPT_Data[i])\n",
    "    #    #plt.matshow(PL_Data[i])\n",
    "    #    #plt.show()\n",
    "    \n",
    "    print(\"SPLT Features\")\n",
    "    # Plot Packet Lengths rate\n",
    "    fig9 = plt.figure(9, figsize=(15, 10))\n",
    "    pl91 = fig9.add_subplot(411)\n",
    "    pl91.bar(range(len(IPT_Data_Min)), IPT_Data_Min,color=\"g\")\n",
    "    pl91.set_title(\"Inner Packet Time Min\") \n",
    "    pl92 = fig9.add_subplot(412)\n",
    "    pl92.bar(range(len(IPT_Data_Max)), IPT_Data_Max,color=\"g\")\n",
    "    pl92.set_title(\"Inner Packet Time Max\")\n",
    "    pl93 = fig9.add_subplot(413)\n",
    "    pl93.bar(range(len(IPT_Data_Mean)), IPT_Data_Mean,color=\"g\")\n",
    "    pl93.set_title(\"Inner Packet Time Mean\")\n",
    "    pl94 = fig9.add_subplot(414)\n",
    "    pl94.bar(range(len(IPT_Data_Median)), IPT_Data_Median,color=\"g\")\n",
    "    pl94.set_title(\"Inner Packet Time Median\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot Packet Lengths rate\n",
    "    fig10 = plt.figure(10, figsize=(15, 10))\n",
    "    pl101 = fig10.add_subplot(411)\n",
    "    pl101.bar(range(len(PL_Data_Min)), PL_Data_Min,color=\"g\")\n",
    "    pl101.set_title(\"Individual Packet Length Min\") \n",
    "    pl102 = fig10.add_subplot(412)\n",
    "    pl102.bar(range(len(PL_Data_Max)), PL_Data_Max,color=\"g\")\n",
    "    pl102.set_title(\"Individual Packet Length Max\")\n",
    "    pl103 = fig10.add_subplot(413)\n",
    "    pl103.bar(range(len(PL_Data_Mean)), PL_Data_Mean,color=\"g\")\n",
    "    pl103.set_title(\"Individual Packet Length Mean\")\n",
    "    pl104 = fig10.add_subplot(414)\n",
    "    pl104.bar(range(len(PL_Data_Median)), PL_Data_Median,color=\"g\")\n",
    "    pl104.set_title(\"Individual Packet Length Median\")\n",
    "    plt.show()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
