{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "#from data_parser import DataParser\n",
    "from pull_data import Pull\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#from scikit_IsolatedForest import IsolatedForest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "#from scikit_LOFNovelty import LOFNovelty\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "#from scikit_OneClassSVM import OCSVM\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IKEA_APP = \"dev-annotated-datasets/ikea-app\"\n",
    "IKEA_HOMEKIT = \"dev-annotated-datasets/ikea-homekit\"\n",
    "IP_CAM = \"dev-annotated-datasets/ipcam\"\n",
    "NORMAL_USER = \"dev-annotated-datasets/normal-user\"\n",
    "VOICE_ASSISTANT = \"dev-annotated-datasets/voice-assistant\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y, pred, thr_pred=0.5, label=\"\"):\n",
    "    #mse = metrics.mean_squared_error(y, pred) # MSE of (y - pred) is the same as Brier score\n",
    "#    brier = metrics.brier_score_loss(y, pred)\n",
    "    #logloss = metrics.log_loss(y, pred)\n",
    "    print(\"### Metric\",label,\"###\")\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "    except Exception as e:\n",
    "        # TN in all cases\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tp = confusion_matrix(y, pred).ravel()[0]\n",
    "    #print(tn, fp, fn, tp)\n",
    "    \n",
    "    total = tp+tn+fp+fn\n",
    "    acc = (tp+tn)/total\n",
    "    if label == \"valid\":\n",
    "        prec = tp/(tp+fp)\n",
    "        rec = tp/(tp+fn)\n",
    "        f1 = 2*(prec*rec)/(prec+rec)\n",
    "    \n",
    "        print(\"TP: {:7d} {:6.2f}%\".format(tp, tp*100/total))\n",
    "        print(\"FN: {:7d} {:6.2f}%\".format(fn, fn*100/total))\n",
    "        print(\"FP: {:7d} {:6.2f}%\".format(fp, fp*100/total))\n",
    "        print(\"TN: {:7d} {:6.2f}%\".format(tn, tn*100/total))\n",
    "        print(\"Accuracy:   {:6.2f}%\".format(acc*100))\n",
    "        print(\"Precision:  {:6.4f}\".format(prec))\n",
    "        print(\"Recall:     {:6.4f}\".format(rec))\n",
    "    \n",
    "        print(\"F1 score:   {:6.4f}\".format(f1))\n",
    "    \n",
    "    else:\n",
    "        prec_n = tn/(tn+fn)\n",
    "        rec_n = tn/(tn+fp)\n",
    "        f1_n = 2*(prec_n*rec_n)/(prec_n+rec_n)\n",
    "        print(\"TP: {:7d} {:6.2f}%\".format(tp, tp*100/total))\n",
    "        print(\"FN: {:7d} {:6.2f}%\".format(fn, fn*100/total))\n",
    "        print(\"FP: {:7d} {:6.2f}%\".format(fp, fp*100/total))\n",
    "        print(\"TN: {:7d} {:6.2f}%\".format(tn, tn*100/total))\n",
    "        print(\"Accuracy:   {:6.2f}%\".format(acc*100))\n",
    "        print(\"Precision Anomaly:  {:6.4f}\".format(prec_n))\n",
    "        print(\"Recall Anomaly:     {:6.4f}\".format(rec_n))\n",
    "        print(\"F1 score Anomaly:   {:6.4f}\".format(f1_n))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388 9 0\n"
     ]
    }
   ],
   "source": [
    "t = Pull(IKEA_APP+\"/train/\",1)\n",
    "a = Pull(IKEA_APP+\"/anomaly/\",1)\n",
    "v = Pull(IKEA_APP+\"/valid/\",1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolated Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Iteration: 1 =====\n",
      "### Metric valid ###\n",
      "TP:      76  97.44%\n",
      "FN:       2   2.56%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:    97.44%\n",
      "Precision:  1.0000\n",
      "Recall:     0.9744\n",
      "F1 score:   0.9870\n",
      "### Metric anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       8  88.89%\n",
      "TN:       1  11.11%\n",
      "Accuracy:    11.11%\n",
      "Precision Anomaly:  1.0000\n",
      "Recall Anomaly:     0.1111\n",
      "F1 score Anomaly:   0.2000\n",
      "===== Iteration: 2 =====\n",
      "### Metric valid ###\n",
      "TP:      77  98.72%\n",
      "FN:       1   1.28%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:    98.72%\n",
      "Precision:  1.0000\n",
      "Recall:     0.9872\n",
      "F1 score:   0.9935\n",
      "### Metric anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       6  66.67%\n",
      "TN:       3  33.33%\n",
      "Accuracy:    33.33%\n",
      "Precision Anomaly:  1.0000\n",
      "Recall Anomaly:     0.3333\n",
      "F1 score Anomaly:   0.5000\n",
      "===== Iteration: 3 =====\n",
      "### Metric valid ###\n",
      "TP:      78 100.00%\n",
      "FN:       0   0.00%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:   100.00%\n",
      "Precision:  1.0000\n",
      "Recall:     1.0000\n",
      "F1 score:   1.0000\n",
      "### Metric anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       8  88.89%\n",
      "TN:       1  11.11%\n",
      "Accuracy:    11.11%\n",
      "Precision Anomaly:  1.0000\n",
      "Recall Anomaly:     0.1111\n",
      "F1 score Anomaly:   0.2000\n",
      "===== Iteration: 4 =====\n",
      "### Metric valid ###\n",
      "TP:      73  94.81%\n",
      "FN:       4   5.19%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:    94.81%\n",
      "Precision:  1.0000\n",
      "Recall:     0.9481\n",
      "F1 score:   0.9733\n",
      "### Metric anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       8  88.89%\n",
      "TN:       1  11.11%\n",
      "Accuracy:    11.11%\n",
      "Precision Anomaly:  1.0000\n",
      "Recall Anomaly:     0.1111\n",
      "F1 score Anomaly:   0.2000\n",
      "===== Iteration: 5 =====\n",
      "### Metric valid ###\n",
      "TP:      77 100.00%\n",
      "FN:       0   0.00%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:   100.00%\n",
      "Precision:  1.0000\n",
      "Recall:     1.0000\n",
      "F1 score:   1.0000\n",
      "### Metric anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       6  66.67%\n",
      "TN:       3  33.33%\n",
      "Accuracy:    33.33%\n",
      "Precision Anomaly:  1.0000\n",
      "Recall Anomaly:     0.3333\n",
      "F1 score Anomaly:   0.5000\n"
     ]
    }
   ],
   "source": [
    "#Create Model\n",
    "rng = np.random.RandomState(12345)\n",
    "clf = IsolationForest(n_estimators = 100, max_samples=\"auto\",max_features=1,bootstrap=False ,random_state=rng, behaviour='new', contamination='auto')\n",
    "\n",
    "#Train \n",
    "#clf.fit(t.data)\n",
    "\n",
    "#Evaluate \n",
    "#y_pred_valid = clf.predict(v.data)\n",
    "#y_pred_outliers = clf.predict(a.data)\n",
    "\n",
    "# Measurement\n",
    "#print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"valid\")\n",
    "#print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"anomaly\")\n",
    "# Detection quality score ( The lower, the more abnormal. Negative scores represent outliers, positive scores represent inliers.) \n",
    "#score_v = clf.decision_function(v.data)\n",
    "#score_a = clf.decision_function(a.data)\n",
    "#print(score_v)\n",
    "#print(score_a)\n",
    "\n",
    "kf = KFold(5, True)\n",
    "t_data = np.array(t.data)\n",
    "a_data = np.array(a.data)\n",
    "iteration_cnt = 0\n",
    "for train_index, test_index in kf.split(t_data):\n",
    "    iteration_cnt += 1\n",
    "    #Train\n",
    "    clf.fit(t_data[train_index])\n",
    "    #Evaluate \n",
    "    y_pred_valid = clf.predict(t_data[test_index])\n",
    "    y_pred_outliers = clf.predict(a.data)\n",
    "    print(\"===== Iteration:\",iteration_cnt,\"=====\")\n",
    "    print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"valid\")\n",
    "    print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"anomaly\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOF Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Iteration: 1 =====\n",
      "### Metric valid ###\n",
      "TP:      61  78.21%\n",
      "FN:      17  21.79%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:    78.21%\n",
      "Precision:  1.0000\n",
      "Recall:     0.7821\n",
      "F1 score:   0.8777\n",
      "### Metric anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       8  88.89%\n",
      "TN:       1  11.11%\n",
      "Accuracy:    11.11%\n",
      "Precision Anomaly:  1.0000\n",
      "Recall Anomaly:     0.1111\n",
      "F1 score Anomaly:   0.2000\n",
      "===== Iteration: 2 =====\n",
      "### Metric valid ###\n",
      "TP:      62  79.49%\n",
      "FN:      16  20.51%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:    79.49%\n",
      "Precision:  1.0000\n",
      "Recall:     0.7949\n",
      "F1 score:   0.8857\n",
      "### Metric anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       8  88.89%\n",
      "TN:       1  11.11%\n",
      "Accuracy:    11.11%\n",
      "Precision Anomaly:  1.0000\n",
      "Recall Anomaly:     0.1111\n",
      "F1 score Anomaly:   0.2000\n",
      "===== Iteration: 3 =====\n",
      "### Metric valid ###\n",
      "TP:      63  80.77%\n",
      "FN:      15  19.23%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:    80.77%\n",
      "Precision:  1.0000\n",
      "Recall:     0.8077\n",
      "F1 score:   0.8936\n",
      "### Metric anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       8  88.89%\n",
      "TN:       1  11.11%\n",
      "Accuracy:    11.11%\n",
      "Precision Anomaly:  1.0000\n",
      "Recall Anomaly:     0.1111\n",
      "F1 score Anomaly:   0.2000\n",
      "===== Iteration: 4 =====\n",
      "### Metric valid ###\n",
      "TP:      61  79.22%\n",
      "FN:      16  20.78%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:    79.22%\n",
      "Precision:  1.0000\n",
      "Recall:     0.7922\n",
      "F1 score:   0.8841\n",
      "### Metric anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       8  88.89%\n",
      "TN:       1  11.11%\n",
      "Accuracy:    11.11%\n",
      "Precision Anomaly:  1.0000\n",
      "Recall Anomaly:     0.1111\n",
      "F1 score Anomaly:   0.2000\n",
      "===== Iteration: 5 =====\n",
      "### Metric valid ###\n",
      "TP:      63  81.82%\n",
      "FN:      14  18.18%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:    81.82%\n",
      "Precision:  1.0000\n",
      "Recall:     0.8182\n",
      "F1 score:   0.9000\n",
      "### Metric anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       8  88.89%\n",
      "TN:       1  11.11%\n",
      "Accuracy:    11.11%\n",
      "Precision Anomaly:  1.0000\n",
      "Recall Anomaly:     0.1111\n",
      "F1 score Anomaly:   0.2000\n"
     ]
    }
   ],
   "source": [
    "#Create Model\n",
    "clf = LocalOutlierFactor(n_neighbors = 20, metric = \"chebyshev\", novelty=True, contamination='auto')\n",
    "\n",
    "#Train \n",
    "#clf.fit(t.data)\n",
    "\n",
    "#Evaluate \n",
    "#y_pred_valid = clf.predict(v.data)\n",
    "#y_pred_outliers = clf.predict(a.data)\n",
    "\n",
    "# Measurement\n",
    "#print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"valid\")\n",
    "#print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"anomaly\")\n",
    "# Detection quality score ( The lower, the more abnormal. Negative scores represent outliers, positive scores represent inliers.) \n",
    "#score_v = clf.decision_function(v.data)\n",
    "#score_a = clf.decision_function(a.data)\n",
    "#print(score_v)\n",
    "#print(score_a)\n",
    "\n",
    "kf = KFold(5, True)\n",
    "t_data = np.array(t.data)\n",
    "a_data = np.array(a.data)\n",
    "iteration_cnt = 0\n",
    "for train_index, test_index in kf.split(t_data):\n",
    "    iteration_cnt += 1\n",
    "    #Train\n",
    "    clf.fit(t_data[train_index])\n",
    "    #Evaluate \n",
    "    y_pred_valid = clf.predict(t_data[test_index])\n",
    "    y_pred_outliers = clf.predict(a.data)\n",
    "    print(\"===== Iteration:\",iteration_cnt,\"=====\")\n",
    "    print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"valid\")\n",
    "    print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"anomaly\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Iteration: 1 =====\n",
      "### Metric valid ###\n",
      "TP:      78 100.00%\n",
      "FN:       0   0.00%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:   100.00%\n",
      "Precision:  1.0000\n",
      "Recall:     1.0000\n",
      "F1 score:   1.0000\n",
      "### Metric anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       9 100.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:     0.00%\n",
      "Precision Anomaly:     nan\n",
      "Recall Anomaly:     0.0000\n",
      "F1 score Anomaly:      nan\n",
      "===== Iteration: 2 =====\n",
      "### Metric valid ###\n",
      "TP:      78 100.00%\n",
      "FN:       0   0.00%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:   100.00%\n",
      "Precision:  1.0000\n",
      "Recall:     1.0000\n",
      "F1 score:   1.0000\n",
      "### Metric anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       9 100.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:     0.00%\n",
      "Precision Anomaly:     nan\n",
      "Recall Anomaly:     0.0000\n",
      "F1 score Anomaly:      nan\n",
      "===== Iteration: 3 =====\n",
      "### Metric valid ###\n",
      "TP:      78 100.00%\n",
      "FN:       0   0.00%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:   100.00%\n",
      "Precision:  1.0000\n",
      "Recall:     1.0000\n",
      "F1 score:   1.0000\n",
      "### Metric anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       9 100.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:     0.00%\n",
      "Precision Anomaly:     nan\n",
      "Recall Anomaly:     0.0000\n",
      "F1 score Anomaly:      nan\n",
      "===== Iteration: 4 =====\n",
      "### Metric valid ###\n",
      "TP:       0   0.00%\n",
      "FN:      77 100.00%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:     0.00%\n",
      "Precision:     nan\n",
      "Recall:     0.0000\n",
      "F1 score:      nan\n",
      "### Metric anomaly ###\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:34: RuntimeWarning: invalid value encountered in long_scalars\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-dd65851bf5fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"===== Iteration:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miteration_cnt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"=====\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mprint_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred_outliers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_outliers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"anomaly\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-8eead38c258a>\u001b[0m in \u001b[0;36mprint_metrics\u001b[0;34m(y, pred, thr_pred, label)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mprec_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mrec_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtn\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mf1_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec_n\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mrec_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprec_n\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrec_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "#Create Model\n",
    "clf = OneClassSVM(kernel='sigmoid',gamma=\"auto\",coef0=0.0, nu=0.1)\n",
    "\n",
    "#Train \n",
    "#clf.fit(t.data)\n",
    "\n",
    "#Evaluate \n",
    "#y_pred_valid = clf.predict(v.data)\n",
    "#y_pred_outliers = clf.predict(a.data)\n",
    "\n",
    "# Measurement\n",
    "#print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"valid\")\n",
    "#print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"anomaly\")\n",
    "# Detection quality score ( Signed distance is positive for an inlier and negative for an outlier.) \n",
    "#score_v = clf.decision_function(v.data)\n",
    "#score_a = clf.decision_function(a.data)\n",
    "#print(score_v)\n",
    "#print(score_a)\n",
    "\n",
    "kf = KFold(5, True)\n",
    "t_data = np.array(t.data)\n",
    "a_data = np.array(a.data)\n",
    "iteration_cnt = 0\n",
    "for train_index, test_index in kf.split(t_data):\n",
    "    iteration_cnt += 1\n",
    "    #Train\n",
    "    clf.fit(t_data[train_index])\n",
    "    #Evaluate \n",
    "    y_pred_valid = clf.predict(t_data[test_index])\n",
    "    y_pred_outliers = clf.predict(a.data)\n",
    "    print(\"===== Iteration:\",iteration_cnt,\"=====\")\n",
    "    print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"valid\")\n",
    "    print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"anomaly\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
