{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "#from data_parser import DataParser\n",
    "from pull_data import Pull\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from prettytable import PrettyTable\n",
    "from statistics import mean\n",
    "\n",
    "#from scikit_IsolatedForest import IsolatedForest\n",
    "from sklearn.ensemble import IsolationForest\n",
    "#from scikit_LOFNovelty import LOFNovelty\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "#from scikit_OneClassSVM import OCSVM\n",
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IKEA_APP = \"dev-annotated-datasets/ikea-app\"\n",
    "IKEA_HOMEKIT = \"dev-annotated-datasets/ikea-homekit\"\n",
    "IP_CAM = \"dev-annotated-datasets/ipcam\"\n",
    "NORMAL_USER = \"dev-annotated-datasets/normal-user\"\n",
    "VOICE_ASSISTANT = \"dev-annotated-datasets/voice-assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metrics:\n",
    "    def __init__(self,label):\n",
    "        self.label = label\n",
    "        self.accuracy = []\n",
    "        self.precision = []\n",
    "        self.recall = []\n",
    "        self.f1 = []\n",
    "        self.cnt = 0\n",
    "    def update(self,y,pred):\n",
    "        try:\n",
    "            tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "        except Exception as e:\n",
    "            # TN in all cases\n",
    "            tn = 0\n",
    "            fp = 0\n",
    "            fn = 0\n",
    "            tp = confusion_matrix(y, pred).ravel()[0]\n",
    "        \n",
    "        total = tp+tn+fp+fn\n",
    "        accuracy = (tp+tn)/total\n",
    "        if self.label == \"Valid\":\n",
    "            precision = tp/(tp+fp)\n",
    "            recall = tp/(tp+fn)\n",
    "            f1 = 2*(precision*recall)/(precision+recall)\n",
    "        else:\n",
    "            try:\n",
    "                precision = tn/(tn+fn) # Negative precision\n",
    "                recall = tn/(tn+fp) # Negative recall\n",
    "                f1 = 2*(precision*recall)/(precision+recall) # Negative f1\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                precision = 0\n",
    "                f1 = 0\n",
    "                recall = 0\n",
    "        \n",
    "        self.accuracy.append(accuracy)\n",
    "        self.precision.append(precision)\n",
    "        self.recall.append(recall)\n",
    "        self.f1.append(f1)\n",
    "        self.cnt += 1\n",
    "        \n",
    "    def print(self):\n",
    "        table = PrettyTable()\n",
    "        table.field_names = [self.label+\" Data\",\"Accuracy\", \"Precision\", \"Recall\", \"F1 score\"]\n",
    "        for i in range(len(self.accuracy)):\n",
    "            table.add_row([i,round(self.accuracy[i],3),round(self.precision[i],3),round(self.recall[i],3),round(self.f1[i],3)])\n",
    "        \n",
    "        table.add_row([\"Avg\",round(mean(self.accuracy),3),round(mean(self.precision),3),round(mean(self.recall),3),round(mean(self.f1),3)])\n",
    "        print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y, pred, thr_pred=0.5, label=\"\"):\n",
    "    #mse = metrics.mean_squared_error(y, pred) # MSE of (y - pred) is the same as Brier score\n",
    "#    brier = metrics.brier_score_loss(y, pred)\n",
    "    #logloss = metrics.log_loss(y, pred)\n",
    "    print(\"### Metric\",label,\"###\")\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y, pred).ravel()\n",
    "    except Exception as e:\n",
    "        # TP in all cases\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tp = confusion_matrix(y, pred).ravel()[0]\n",
    "    #print(tn, fp, fn, tp)\n",
    "    \n",
    "    total = tp+tn+fp+fn\n",
    "    acc = (tp+tn)/total\n",
    "    if label == \"Valid\":\n",
    "        prec = tp/(tp+fp)\n",
    "        rec = tp/(tp+fn)\n",
    "        f1 = 2*(prec*rec)/(prec+rec)\n",
    "    \n",
    "        print(\"TP: {:7d} {:6.2f}%\".format(tp, tp*100/total))\n",
    "        print(\"FN: {:7d} {:6.2f}%\".format(fn, fn*100/total))\n",
    "        print(\"FP: {:7d} {:6.2f}%\".format(fp, fp*100/total))\n",
    "        print(\"TN: {:7d} {:6.2f}%\".format(tn, tn*100/total))\n",
    "        print(\"Accuracy:   {:6.2f}%\".format(acc*100))\n",
    "        print(\"Precision:  {:6.4f}\".format(prec))\n",
    "        print(\"Recall:     {:6.4f}\".format(rec))\n",
    "        print(\"F1 score:   {:6.4f}\".format(f1))\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            prec_n = tn/(tn+fn)\n",
    "            rec_n = tn/(tn+fp)\n",
    "            f1_n = 2*(prec_n*rec_n)/(prec_n+rec_n)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            prec_n = 0\n",
    "            f1_n = 0\n",
    "            rec_n = 0\n",
    "        \n",
    "        print(\"TP: {:7d} {:6.2f}%\".format(tp, tp*100/total))\n",
    "        print(\"FN: {:7d} {:6.2f}%\".format(fn, fn*100/total))\n",
    "        print(\"FP: {:7d} {:6.2f}%\".format(fp, fp*100/total))\n",
    "        print(\"TN: {:7d} {:6.2f}%\".format(tn, tn*100/total))\n",
    "        print(\"Accuracy:   {:6.2f}%\".format(acc*100))\n",
    "        print(\"Precision Anomaly:  {:6.4f}\".format(prec_n))\n",
    "        print(\"Recall Anomaly:     {:6.4f}\".format(rec_n))\n",
    "        print(\"F1 score Anomaly:   {:6.4f}\".format(f1_n))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(models):\n",
    "    for key, model in models.items():\n",
    "        print(\"### Model Name:\",key,\" ###\")\n",
    "        m_valid = Metrics(label=\"Valid\")\n",
    "        m_anomaly = Metrics(label=\"Anomaly\")\n",
    "        kf = KFold(5, True)\n",
    "        t_data = np.array(t.data)\n",
    "        a_data = np.array(a.data)\n",
    "        iteration_cnt = 0\n",
    "        for train_index, test_index in kf.split(t_data):\n",
    "            iteration_cnt += 1\n",
    "            #Train\n",
    "            model.fit(t_data[train_index])\n",
    "            #Evaluate \n",
    "            y_pred_valid = model.predict(t_data[test_index])\n",
    "            y_pred_outliers = model.predict(a.data)\n",
    "            # Add results to the metrics object\n",
    "            m_valid.update([1]*len(y_pred_valid),y_pred_valid)\n",
    "            m_anomaly.update([-1]*len(y_pred_outliers),y_pred_outliers)\n",
    "            #print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"Valid\")\n",
    "            #print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"Anomaly\")\n",
    "        m_valid.print()\n",
    "        m_anomaly.print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: failued to parse file dev-annotated-datasets/ikea-app/train/.DS_Store\n",
      "Valid: 388  Anomaly: 16  Valid: 0\n",
      "Number of features: 107\n"
     ]
    }
   ],
   "source": [
    "t = Pull(IKEA_APP +\"/train/\",1)\n",
    "a = Pull(IKEA_APP +\"/anomaly/\",1)\n",
    "v = Pull(IKEA_APP +\"/valid/\",1)\n",
    "print(\"Valid:\",len(t.data),\" Anomaly:\",len(a.data),\" Valid:\",len(v.data))\n",
    "print(\"Number of features:\",t.features_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {}\n",
    "MODELS[\"IsolatedForest\"] = {}\n",
    "MODELS[\"LOF\"] = {}\n",
    "MODELS[\"OneClassSVM\"] = {}\n",
    "rng = np.random.RandomState(12345)\n",
    "MODELS[\"IsolatedForest\"][\"IF1\"] = IsolationForest(n_estimators = 250, max_samples='auto',max_features=5,bootstrap=True , behaviour='new',random_state=rng, contamination='auto')\n",
    "#MODELS[\"IsolatedForest\"][\"IF2\"] = IsolationForest(n_estimators = 20, max_samples='auto',max_features=5,bootstrap=True ,random_state=rng)\n",
    "#MODELS[\"LOF\"][\"LOF1\"] = LocalOutlierFactor(n_neighbors = 10, metric = \"chebyshev\", novelty=True, contamination=0.1)\n",
    "MODELS[\"LOF\"][\"LOF2\"] = LocalOutlierFactor(n_neighbors = 10, metric = \"chebyshev\", novelty=True, contamination='auto')\n",
    "MODELS[\"LOF\"][\"LOF3\"] = LocalOutlierFactor(n_neighbors = 10, metric = \"canberra\", novelty=True, contamination='auto')\n",
    "#MODELS[\"LOF\"][\"LOF4\"] = LocalOutlierFactor(n_neighbors = 10, metric = \"canberra\", novelty=True, contamination='auto')\n",
    "MODELS[\"OneClassSVM\"][\"OSVM1\"] = OneClassSVM(kernel='poly',gamma=\"auto\",coef0=1, nu=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Model Name: LOF2  ###\n",
      "+------------+----------+-----------+--------+----------+\n",
      "| Valid Data | Accuracy | Precision | Recall | F1 score |\n",
      "+------------+----------+-----------+--------+----------+\n",
      "|     0      |  0.859   |    1.0    | 0.859  |  0.924   |\n",
      "|     1      |  0.833   |    1.0    | 0.833  |  0.909   |\n",
      "|     2      |  0.833   |    1.0    | 0.833  |  0.909   |\n",
      "|     3      |   0.87   |    1.0    |  0.87  |  0.931   |\n",
      "|     4      |  0.896   |    1.0    | 0.896  |  0.945   |\n",
      "|    Avg     |  0.858   |    1.0    | 0.858  |  0.924   |\n",
      "+------------+----------+-----------+--------+----------+\n",
      "+--------------+----------+-----------+--------+----------+\n",
      "| Anomaly Data | Accuracy | Precision | Recall | F1 score |\n",
      "+--------------+----------+-----------+--------+----------+\n",
      "|      0       |  0.688   |    1.0    | 0.688  |  0.815   |\n",
      "|      1       |  0.688   |    1.0    | 0.688  |  0.815   |\n",
      "|      2       |  0.688   |    1.0    | 0.688  |  0.815   |\n",
      "|      3       |  0.875   |    1.0    | 0.875  |  0.933   |\n",
      "|      4       |  0.688   |    1.0    | 0.688  |  0.815   |\n",
      "|     Avg      |  0.725   |    1.0    | 0.725  |  0.839   |\n",
      "+--------------+----------+-----------+--------+----------+\n",
      "### Model Name: LOF3  ###\n",
      "division by zero\n",
      "division by zero\n",
      "division by zero\n",
      "+------------+----------+-----------+--------+----------+\n",
      "| Valid Data | Accuracy | Precision | Recall | F1 score |\n",
      "+------------+----------+-----------+--------+----------+\n",
      "|     0      |  0.782   |    1.0    | 0.782  |  0.878   |\n",
      "|     1      |  0.936   |    1.0    | 0.936  |  0.967   |\n",
      "|     2      |  0.936   |    1.0    | 0.936  |  0.967   |\n",
      "|     3      |   0.87   |    1.0    |  0.87  |  0.931   |\n",
      "|     4      |  0.818   |    1.0    | 0.818  |   0.9    |\n",
      "|    Avg     |  0.868   |    1.0    | 0.868  |  0.928   |\n",
      "+------------+----------+-----------+--------+----------+\n",
      "+--------------+----------+-----------+--------+----------+\n",
      "| Anomaly Data | Accuracy | Precision | Recall | F1 score |\n",
      "+--------------+----------+-----------+--------+----------+\n",
      "|      0       |   1.0    |     0     |   0    |    0     |\n",
      "|      1       |  0.938   |    1.0    | 0.938  |  0.968   |\n",
      "|      2       |   1.0    |     0     |   0    |    0     |\n",
      "|      3       |   1.0    |     0     |   0    |    0     |\n",
      "|      4       |  0.938   |    1.0    | 0.938  |  0.968   |\n",
      "|     Avg      |  0.975   |    0.4    | 0.375  |  0.387   |\n",
      "+--------------+----------+-----------+--------+----------+\n"
     ]
    }
   ],
   "source": [
    "#runModel(MODELS[\"IsolatedForest\"])\n",
    "runModel(MODELS[\"LOF\"])\n",
    "#runModel(MODELS[\"OneClassSVM\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolated Forest"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Create Model\n",
    "rng = np.random.RandomState(12345)\n",
    "clf = IsolationForest(n_estimators = 100, max_samples=\"auto\",max_features=1,bootstrap=False ,random_state=rng, behaviour='new', contamination='auto')\n",
    "\n",
    "kf = KFold(3, True)\n",
    "t_data = np.array(t.data)\n",
    "a_data = np.array(a.data)\n",
    "iteration_cnt = 0\n",
    "for train_index, test_index in kf.split(t_data):\n",
    "    iteration_cnt += 1\n",
    "    #Train\n",
    "    clf.fit(t_data[train_index])\n",
    "    #Evaluate \n",
    "    y_pred_valid = clf.predict(t_data[test_index])\n",
    "    y_pred_outliers = clf.predict(a.data)\n",
    "    print(\"===== Iteration:\",iteration_cnt,\"=====\")\n",
    "    print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"Valid\")\n",
    "    print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"Anomaly\")\n",
    "    \n",
    "    #m_valid.update([1]*len(y_pred_valid),y_pred_valid)\n",
    "    #m_anomaly.update([-1]*len(y_pred_outliers),y_pred_outliers)\n",
    "    #m_valid.print()\n",
    "    #m_anomaly.print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOF Novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Iteration: 1 =====\n",
      "### Metric Valid ###\n",
      "TP:      87  78.38%\n",
      "FN:      24  21.62%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:    78.38%\n",
      "Precision:  1.0000\n",
      "Recall:     0.7838\n",
      "F1 score:   0.8788\n",
      "### Metric Anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       4  25.00%\n",
      "TN:      12  75.00%\n",
      "Accuracy:    75.00%\n",
      "Precision Anomaly:  1.0000\n",
      "Recall Anomaly:     0.7500\n",
      "F1 score Anomaly:   0.8571\n",
      "0.5842882001362815\n",
      "===== Iteration: 2 =====\n",
      "### Metric Valid ###\n",
      "TP:      96  86.49%\n",
      "FN:      15  13.51%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:    86.49%\n",
      "Precision:  1.0000\n",
      "Recall:     0.8649\n",
      "F1 score:   0.9275\n",
      "### Metric Anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       6  37.50%\n",
      "TN:      10  62.50%\n",
      "Accuracy:    62.50%\n",
      "Precision Anomaly:  1.0000\n",
      "Recall Anomaly:     0.6250\n",
      "F1 score Anomaly:   0.7692\n",
      "0.565677147539551\n",
      "===== Iteration: 3 =====\n",
      "### Metric Valid ###\n",
      "TP:      98  89.09%\n",
      "FN:      12  10.91%\n",
      "FP:       0   0.00%\n",
      "TN:       0   0.00%\n",
      "Accuracy:    89.09%\n",
      "Precision:  1.0000\n",
      "Recall:     0.8909\n",
      "F1 score:   0.9423\n",
      "### Metric Anomaly ###\n",
      "TP:       0   0.00%\n",
      "FN:       0   0.00%\n",
      "FP:       5  31.25%\n",
      "TN:      11  68.75%\n",
      "Accuracy:    68.75%\n",
      "Precision Anomaly:  1.0000\n",
      "Recall Anomaly:     0.6875\n",
      "F1 score Anomaly:   0.8148\n",
      "0.5451079998612759\n"
     ]
    }
   ],
   "source": [
    "#Create Model\n",
    "clf = LocalOutlierFactor(n_neighbors = 10, metric = \"minkowski\", novelty=True, contamination='auto')\n",
    "\n",
    "kf = KFold(3, True)\n",
    "t_data = np.array(t.data)\n",
    "a_data = np.array(a.data)\n",
    "iteration_cnt = 0\n",
    "for train_index, test_index in kf.split(t_data):\n",
    "    iteration_cnt += 1\n",
    "    #Train\n",
    "    clf.fit(t_data[train_index])\n",
    "    #Evaluate \n",
    "    y_pred_valid = clf.predict(t_data[test_index])\n",
    "    y_pred_outliers = clf.predict(a.data)\n",
    "    print(\"===== Iteration:\",iteration_cnt,\"=====\")\n",
    "    print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"Valid\")\n",
    "    print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"Anomaly\")\n",
    "    score_v = clf.decision_function(t_data[test_index])\n",
    "    score_a = clf.decision_function(a.data)\n",
    "    print(max(score_v))\n",
    "   \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OneClassSVM"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Create Model\n",
    "clf = OneClassSVM(kernel='sigmoid',gamma=\"auto\",coef0=0.0, nu=0.1)\n",
    "\n",
    "kf = KFold(3, True)\n",
    "t_data = np.array(t.data)\n",
    "a_data = np.array(a.data)\n",
    "iteration_cnt = 0\n",
    "for train_index, test_index in kf.split(t_data):\n",
    "    iteration_cnt += 1\n",
    "    #Train\n",
    "    clf.fit(t_data[train_index])\n",
    "    #Evaluate \n",
    "    y_pred_valid = clf.predict(t_data[test_index])\n",
    "    y_pred_outliers = clf.predict(a.data)\n",
    "    print(\"===== Iteration:\",iteration_cnt,\"=====\")\n",
    "    print_metrics([1]*len(y_pred_valid),y_pred_valid,label=\"Valid\")\n",
    "    print_metrics([-1]*len(y_pred_outliers),y_pred_outliers,label=\"Anomaly\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
